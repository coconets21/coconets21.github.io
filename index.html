<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CoCoNets: Continuous Contrastive 3D Scene Representations">
  <meta name="keywords" content="Tracking, Implicit, Rendering">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CoCoNets: Continuous Contrastive 3D Scene Representations</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CoCoNets: Continuous Contrastive 3D Scene Representations</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://shamitlal.github.io/">Shamit Lal*</a>,</span>
            <span class="author-block">
              <a href="https://mihirp1998.github.io/">Mihir Prabhudesai*</a>,</span>
            <span class="author-block">
              <a href="https://ishitamed19.github.io/">Ishita Mediratta</a>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.cmu.edu/~aharley/">Adam W Harley</a>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Carnegie Mellon University</span><br/>
            <span style="display: inline-block; padding-top:0.5em;">CVPR 2021</span><br/>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2104.03851.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2104.03851.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/4P7JDHRwxjM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/shamitlal/CoCoNets"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/webpage_teaser.gif" height="130%" width="130%"/><br/><br/>
      
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          This paper explores self-supervised learning of amodal 3D feature representations from RGB and RGB-D posed images and videos, agnostic to object and scene semantic content, and evaluates the resulting scene representations in the downstream tasks of visual correspondence, object tracking, and object detection.</p>
          <p>
           The model infers a latent 3D representation of the scene in the form of 3D feature points, where each continuous world 3D point is mapped to its corresponding feature vector. The model is trained for contrastive view prediction by rendering 3D feature clouds in queried viewpoints and matching against the 3D feature point cloud predicted from the query view. Notably, the representation can be queried for any 3D location, even if it is not visible from the input view. Our model brings together three powerful ideas of recent exciting research work: 3D feature grids as a neural bottleneck for view prediction, implicit functions for handling resolution limitations of 3D grids, and contrastive learning for unsupervised training of feature representations. We show the resulting 3D visual feature representations effectively scale across objects and scenes, imagine information occluded or missing from the input viewpoints, track objects over time, align semantically related objects in 3D, and improve 3D object detection. </p>
           <p>
           We outperform many existing state-of-the-art methods for 3D feature learning and view prediction, which are either limited by 3D grid spatial resolution, do not attempt to build amodal 3D representations, or do not handle combinatorial scene variability due to their non-convolutional bottlenecks.
         </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/4P7JDHRwxjM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<!-- Method Overview. -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Method Overview</h2>
            <img src="static/images/fig1_new.png" width="600"><br/>
            <h2 class="subtitle has-text-justified">
              <p style="font-size:70%"><b>Continuous Convolutional Contrastive 3D Networks (CoCoNets)</b> are trained to lift 2.5D images to 3D feature function grids of the scene by optimizing for view-contrastive prediction. (a) In the top-down path, the model encodes RGB-D images into a 3D feature map M ∈ R w×h×d×c , and uses explicit 3D feature transformations (translation and 3D rotation) to account for changes of viewpoint between the input and target views. (b) In the bottom-up path, we encode the RGB-D of the target viewpoint into a 3D feature cloud. (c) Given continuous 3D world coordinates (X, Y, Z) and its embedded code v(X,Y,Z) inferred via trilinear interpolation, a fully connected network maps the coordinates and the embedded code, to the feature vector of the 3D point at location (X, Y, Z). (d) Metric learning losses in 3D tie the two point cloud representations together.</p>
      </div>
    </div> 
  </div>
</section>
<!-- Method Overview. -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Demo</h2>
        </div>
    </div> 
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body chair-container">
    <div class="container">
      <center>
        <h2 class="title is-4"><span style="background-color:  #424949; color: white; border-radius: 7px; padding-left:10px; padding-right:10px; padding-top:5px; padding-bottom:5px;"> Object Tracking </span></h2><br/>
        Yellow box represents ground truth track. Blue box is the predicted track. IOU is shown on top left.
        <table align=center width="800px">
          
          <tr style="height: 20px;">
            <td colspan="3"></td>
          </tr>
          <tr>
            <td> <img class="rounded" width="360px" height="50px" src="./static/images/track/track1.gif"/> 
            <td> <img class="rounded" width="360px" height="50px" src="./static/images/track/track2.gif"/> 
            </td>
          </tr>
          <tr>
            <td> <img class="rounded" width="360px" height="50px" src="./static/images/track/track3.gif"/> 
            <td> <img class="rounded" width="360px" height="50px" src="./static/images/track/track4.gif"/> 
            </td>
          </tr>
          <tr>
            <td> <img class="rounded" width="360px" height="50px" src="./static/images/track/track5.gif"/> 
            <td> <img class="rounded" width="360px" height="50px" src="./static/images/track/track6.gif"/> 
            </td>
          </tr>
          <tr>
            <td> <img class="rounded" width="360px" height="50px" src="./static/images/track/track7.gif"/> 
            <td> <img class="rounded" width="360px" height="50px" src="./static/images/track/track8.gif"/> 
            </td>
          </tr>
          
          <!-- <tr>
            <td> <img class="rounded" width="260px" height="50px" src="./static/images/pix3d_shapenet_chairs_comparison/images/520.jpg"/>
            <td> <img class="rounded" width=320px height=150px src="./static/images/pix3d_shapenet_chairs_comparison/sdfsrn/520.gif"/> </td>
            <td> <img class="rounded" width=220px height=50px src="./static/images/pix3d_shapenet_chairs_comparison/tars/520.gif"/> </td>
          </tr> -->
          
          <tr style="height: 20px;">
            <td colspan="3"></td>
          </tr>
          <tr>
          </tr>
          <tr></tr>

          
        </table>
      </center>
    </div>
  </div>
  </section><br/><br/><br/><br/><br/>


<section class="hero is-light is-small">
  <div class="hero-body chair-container">
    <div class="container">
      <center>
        <h2 class="title is-4"><span style="background-color:  #424949; color: white; border-radius: 7px; padding-left:10px; padding-right:10px; padding-top:5px; padding-bottom:5px;"> Occupancy Prediction</span></h2><br/>
        <table align=center width="800px" style="background-color:white; border:1px solid;">
          <tr>
            <td> <h1 style="font-size:20px;"><b><center>Ground Truth</center></h1></b></td>
            <td> <h1 style="font-size:20px;"><b><center>Predicted </center></h1></b></td>
            <td> <h1 style="font-size:20px;"><b><center>Ground Truth</center></h1></b></td>
            <td> <h1 style="font-size:20px;"><b><center>Predicted </center></h1></b></td>
          </tr>
          <tr style="height: 20px;">
            <td colspan="3"></td>
          </tr>
          <tr>
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/bench1_gt.gif"/> 
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/bench1_pred.gif"/> 
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/plane1_gt.gif"/> 
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/plane1_pred.gif"/></td>
          </tr>
          <tr>
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/chair1_gt.gif"/> 
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/chair1_pred.gif"/> 
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/chair2_gt.gif"/> 
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/chair2_pred.gif"/></td>
          </tr>
          <tr>
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/tv1_gt.gif"/> 
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/tv1_pred.gif"/> 
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/gun1_gt.gif"/> 
            <td> <img class="rounded" width="200px" height="50px" src="./static/images/occs/gun1_pred.gif"/></td>
          </tr>
          
          <!-- <tr>
            <td> <img class="rounded" width="260px" height="50px" src="./static/images/pix3d_shapenet_chairs_comparison/images/520.jpg"/>
            <td> <img class="rounded" width=320px height=150px src="./static/images/pix3d_shapenet_chairs_comparison/sdfsrn/520.gif"/> </td>
            <td> <img class="rounded" width=220px height=50px src="./static/images/pix3d_shapenet_chairs_comparison/tars/520.gif"/> </td>
          </tr> -->
          
          <tr style="height: 20px;">
            <td colspan="3"></td>
          </tr>
          <tr>
          </tr>
          <tr></tr>

          
        </table>
      </center>
    </div>
  </div>
  </section><br/><br/><br/><br/><br/>


<section class="hero is-light is-small">
  <div class="hero-body chair-container">
    <div class="container">
      <center>
        <h2 class="title is-4"><span style="background-color:  #424949; color: white; border-radius: 7px; padding-left:10px; padding-right:10px; padding-top:5px; padding-bottom:5px;"> Novel Viewpoint Rendering</span></h2><br/>
        <img src="./static/images/rendering.png" width=50% height=50% style="background-color:white; border:1px solid;">
        </table> 
      </center>
    </div>
  </div>
  </section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{lal2021coconets,
  title={CoCoNets: Continuous contrastive 3D scene representations},
  author={Lal, Shamit and Prabhudesai, Mihir and Mediratta, Ishita and Harley, Adam W and Fragkiadaki, Katerina},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12487--12496},
  year={2021}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>Page template borrowed from <a href="https://github.com/nerfies/nerfies.github.io"><span class="nerfies">Nerfies</span></a>.</p>
    </div>
  </div>
</footer>


</body>
</html>
